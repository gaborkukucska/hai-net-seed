# HAI-Net Implementation Roadmap & Codebase Structure

## Development Roadmap

### Phase 0: Foundation (Weeks 1-4)
```yaml
week_1:
  setup:
    - Repository structure creation
    - Development environment setup
    - CI/CD pipeline configuration
    - Testing framework setup
  
  core_modules:
    - Identity system (DID generation)
    - Basic networking layer
    - Configuration management
    - Logging system

week_2:
  networking:
    - mDNS local discovery
    - P2P communication protocol
    - Encryption layer
    - Message queue system
  
  storage:
    - SQLite setup for local data
    - Vector database integration
    - Distributed storage framework
    - Encryption at rest

week_3:
  ai_foundation:
    - LLM API abstraction layer
    - Ollama/llama.cpp integration
    - Basic agent state machine
    - Memory system foundation

week_4:
  ui_foundation:
    - Web server setup (FastAPI)
    - WebSocket implementation
    - Basic React UI scaffold
    - WebGPU visualization prep
```

### Phase 1: MVP (Weeks 5-8)
```yaml
week_5_6:
  agent_system:
    - Admin agent implementation
    - Basic heartbeat system
    - State management
    - Constitutional core
  
  master_slave:
    - Node role detection
    - Resource discovery
    - Task distribution
    - Basic coordination

week_7_8:
  user_interface:
    - 4-page UI implementation
    - WebGPU visualization
    - Feed system
    - Settings management
  
  integration:
    - End-to-end testing
    - Docker containerization
    - Installation scripts
    - Documentation
```

### Phase 2: Alpha (Weeks 9-12)
```yaml
week_9_10:
  advanced_features:
    - Manager/Worker agents
    - Guardian agent
    - Workflow system
    - MCP tool servers

week_11_12:
  network_features:
    - DHT integration
    - Resource sharing protocol
    - Social networking layer
    - AI-to-AI communication
```

## Codebase Structure

```bash
hai-net/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE (Open Source)
â”œâ”€â”€ CONSTITUTION.md (Immutable principles)
â”œâ”€â”€ .env.example
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt (Python deps)
â”œâ”€â”€ package.json (Node.js deps)
â”‚
â”œâ”€â”€ install/
â”‚   â”œâ”€â”€ install.sh (Unix installer)
â”‚   â”œâ”€â”€ install.ps1 (Windows installer)
â”‚   â”œâ”€â”€ install.py (Cross-platform)
â”‚   â”œâ”€â”€ bootstrap.py (Minimal setup)
â”‚   â””â”€â”€ mobile/
â”‚       â”œâ”€â”€ termux-setup.sh
â”‚       â””â”€â”€ android-slave.sh
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ identity/
â”‚   â”‚   â”œâ”€â”€ did.py
â”‚   â”‚   â”œâ”€â”€ encryption.py
â”‚   â”‚   â””â”€â”€ watermark.py
â”‚   â”‚
â”‚   â”œâ”€â”€ network/
â”‚   â”‚   â”œâ”€â”€ discovery.py (mDNS)
â”‚   â”‚   â”œâ”€â”€ p2p.py (libp2p)
â”‚   â”‚   â”œâ”€â”€ dht.py (Kademlia)
â”‚   â”‚   â”œâ”€â”€ transport.py
â”‚   â”‚   â””â”€â”€ security.py
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ local_db.py (SQLite)
â”‚   â”‚   â”œâ”€â”€ vector_store.py (Qdrant)
â”‚   â”‚   â”œâ”€â”€ distributed.py (IPFS)
â”‚   â”‚   â”œâ”€â”€ cache.py (Redis/KeyDB)
â”‚   â”‚   â””â”€â”€ knowledge.py (Kiwix)
â”‚   â”‚
â”‚   â””â”€â”€ constitutional/
â”‚       â”œâ”€â”€ principles.py
â”‚       â”œâ”€â”€ guardian.py
â”‚       â”œâ”€â”€ enforcement.py
â”‚       â””â”€â”€ education.py
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”œâ”€â”€ hierarchy/
â”‚   â”‚   â”œâ”€â”€ admin.py
â”‚   â”‚   â”œâ”€â”€ manager.py
â”‚   â”‚   â””â”€â”€ worker.py
â”‚   â”‚
â”‚   â”œâ”€â”€ states/
â”‚   â”‚   â”œâ”€â”€ state_machine.py
â”‚   â”‚   â”œâ”€â”€ idle.py
â”‚   â”‚   â”œâ”€â”€ startup.py
â”‚   â”‚   â”œâ”€â”€ planning.py
â”‚   â”‚   â”œâ”€â”€ conversation.py
â”‚   â”‚   â”œâ”€â”€ work.py
â”‚   â”‚   â””â”€â”€ maintenance.py
â”‚   â”‚
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ research.py
â”‚   â”‚   â”œâ”€â”€ development.py
â”‚   â”‚   â”œâ”€â”€ analysis.py
â”‚   â”‚   â”œâ”€â”€ creative.py
â”‚   â”‚   â””â”€â”€ social.py
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ short_term.py
â”‚   â”‚   â”œâ”€â”€ long_term.py
â”‚   â”‚   â”œâ”€â”€ episodic.py
â”‚   â”‚   â””â”€â”€ semantic.py
â”‚   â”‚
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ mcp_server.py
â”‚       â”œâ”€â”€ tool_registry.py
â”‚       â””â”€â”€ builtin_tools.py
â”‚
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ api_wrapper.py
â”‚   â”‚   â”œâ”€â”€ ollama_client.py
â”‚   â”‚   â”œâ”€â”€ llama_cpp.py
â”‚   â”‚   â”œâ”€â”€ vllm_client.py
â”‚   â”‚   â””â”€â”€ model_manager.py
â”‚   â”‚
â”‚   â”œâ”€â”€ voice/
â”‚   â”‚   â”œâ”€â”€ whisper_stt.py
â”‚   â”‚   â”œâ”€â”€ piper_tts.py
â”‚   â”‚   â””â”€â”€ audio_processor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ vision/
â”‚   â”‚   â”œâ”€â”€ comfyui_client.py
â”‚   â”‚   â”œâ”€â”€ image_analysis.py
â”‚   â”‚   â””â”€â”€ video_processor.py
â”‚   â”‚
â”‚   â””â”€â”€ marketplace/
â”‚       â”œâ”€â”€ agent_creator.py
â”‚       â”œâ”€â”€ agent_scorer.py
â”‚       â”œâ”€â”€ model_tester.py
â”‚       â””â”€â”€ federated_learning.py
â”‚
â”œâ”€â”€ hub/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ master/
â”‚   â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”‚   â”œâ”€â”€ resource_manager.py
â”‚   â”‚   â”œâ”€â”€ task_scheduler.py
â”‚   â”‚   â””â”€â”€ failover.py
â”‚   â”‚
â”‚   â”œâ”€â”€ slave/
â”‚   â”‚   â”œâ”€â”€ executor.py
â”‚   â”‚   â”œâ”€â”€ capability_reporter.py
â”‚   â”‚   â””â”€â”€ resource_contributor.py
â”‚   â”‚
â”‚   â””â”€â”€ mesh/
â”‚       â”œâ”€â”€ local_mesh.py
â”‚       â”œâ”€â”€ hub_connector.py
â”‚       â””â”€â”€ topology_manager.py
â”‚
â”œâ”€â”€ social/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ai_to_ai.py
â”‚   â”œâ”€â”€ relationship_manager.py
â”‚   â”œâ”€â”€ event_coordinator.py
â”‚   â””â”€â”€ privacy_filter.py
â”‚
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ local_allocator.py
â”‚   â”œâ”€â”€ surplus_manager.py
â”‚   â”œâ”€â”€ project_contributor.py
â”‚   â””â”€â”€ impact_calculator.py
â”‚
â”œâ”€â”€ blockchain/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ledger.py
â”‚   â”œâ”€â”€ consensus.py
â”‚   â”œâ”€â”€ smart_contracts.py
â”‚   â””â”€â”€ audit_trail.py
â”‚
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ server.py (FastAPI)
â”‚   â”œâ”€â”€ websocket.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â”œâ”€â”€ system.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”‚
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ (React build output)
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ webpack.config.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.tsx
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Visualization.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Feed.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Logs.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Settings.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ BottomNav.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ WebGPURenderer.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MediaButton.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Terminal.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ websocket.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts
â”‚   â”‚   â”‚   â””â”€â”€ wgpu.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ encryption.ts
â”‚   â”‚       â””â”€â”€ helpers.ts
â”‚   â”‚
â”‚   â””â”€â”€ public/
â”‚       â””â”€â”€ index.html
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ e2e/
â”‚   â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_dev.sh
â”‚   â”œâ”€â”€ build.sh
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â””â”€â”€ health_check.py
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ architecture.md
    â”œâ”€â”€ api.md
    â”œâ”€â”€ deployment.md
    â””â”€â”€ contributing.md
```

## Initial Implementation Code

### Core Identity System
```python
# core/identity/did.py
import hashlib
import json
import time
from cryptography.fernet import Fernet
from typing import Dict, Optional

class IdentityManager:
    """
    Manages user identity and DID generation
    """
    
    def __init__(self):
        self.identity = None
        self.encryption_key = None
        
    def create_identity(
        self,
        full_name: str,
        date_of_birth: str,
        gov_id: str,
        passphrase: str,
        email: str
    ) -> Dict:
        """
        Create user DID from personal information
        """
        # Validate email
        if not self._validate_email(email):
            raise ValueError("Invalid email address")
        
        # Create deterministic seed
        seed_data = f"{full_name}|{date_of_birth}|{gov_id}|{passphrase}"
        seed_hash = hashlib.sha256(seed_data.encode()).hexdigest()
        
        # Generate DID
        did = f"did:hai:{seed_hash[:16]}"
        
        # Generate encryption key from seed
        self.encryption_key = Fernet.generate_key()
        
        # Create identity object
        self.identity = {
            "did": did,
            "created": time.time(),
            "email_hash": hashlib.sha256(email.encode()).hexdigest(),
            "public_key": self._generate_public_key(seed_hash),
            "private_key_encrypted": self._encrypt_private_key(seed_hash)
        }
        
        # Save identity
        self._save_identity()
        
        return self.identity
    
    def watermark_data(self, data: bytes) -> bytes:
        """
        Add invisible watermark to data created by AI
        """
        watermark = self.identity["did"].encode()
        # Implement steganographic watermarking
        return self._embed_watermark(data, watermark)
```

### Agent State Machine
```python
# agents/states/state_machine.py
from enum import Enum
from typing import Dict, Optional, Callable
import asyncio

class AgentState(Enum):
    IDLE = "idle"
    STARTUP = "startup"
    PLANNING = "planning"
    CONVERSATION = "conversation"
    WORK = "work"
    MAINTENANCE = "maintenance"

class StateMachine:
    """
    Agent state management with transitions
    """
    
    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.current_state = AgentState.IDLE
        self.state_handlers = {}
        self.transition_rules = self._define_transitions()
        self.state_history = []
        
    def _define_transitions(self) -> Dict:
        """
        Define valid state transitions
        """
        return {
            AgentState.IDLE: [
                AgentState.STARTUP,
                AgentState.PLANNING,
                AgentState.CONVERSATION,
                AgentState.MAINTENANCE
            ],
            AgentState.STARTUP: [
                AgentState.PLANNING,
                AgentState.IDLE
            ],
            AgentState.PLANNING: [
                AgentState.CONVERSATION,
                AgentState.WORK,
                AgentState.MAINTENANCE,
                AgentState.IDLE
            ],
            AgentState.CONVERSATION: [
                AgentState.WORK,
                AgentState.PLANNING,
                AgentState.IDLE
            ],
            AgentState.WORK: [
                AgentState.CONVERSATION,
                AgentState.PLANNING,
                AgentState.IDLE
            ],
            AgentState.MAINTENANCE: [
                AgentState.PLANNING,
                AgentState.IDLE
            ]
        }
    
    async def transition(self, new_state: AgentState, context: Dict = None):
        """
        Transition to new state with validation
        """
        # Check if transition is valid
        if new_state not in self.transition_rules[self.current_state]:
            raise ValueError(
                f"Invalid transition from {self.current_state} to {new_state}"
            )
        
        # Save to history
        self.state_history.append({
            "from": self.current_state,
            "to": new_state,
            "timestamp": asyncio.get_event_loop().time(),
            "context": context
        })
        
        # Execute exit handler for current state
        if self.current_state in self.state_handlers:
            await self.state_handlers[self.current_state]["exit"](context)
        
        # Transition
        old_state = self.current_state
        self.current_state = new_state
        
        # Execute entry handler for new state
        if new_state in self.state_handlers:
            await self.state_handlers[new_state]["entry"](context)
        
        return {
            "success": True,
            "from": old_state,
            "to": new_state
        }
```

### Heartbeat System
```python
# agents/heartbeat.py
import asyncio
import time
from typing import Dict, List
import logging

class HeartbeatSystem:
    """
    CRON-based heartbeat for agent activation
    """
    
    def __init__(self, agent_manager):
        self.agent_manager = agent_manager
        self.interval = 300  # 5 minutes
        self.running = False
        self.logger = logging.getLogger(__name__)
        
    async def start(self):
        """
        Start heartbeat loop
        """
        self.running = True
        self.logger.info("Heartbeat system started")
        
        while self.running:
            try:
                await self._heartbeat_cycle()
                await asyncio.sleep(self.interval)
            except Exception as e:
                self.logger.error(f"Heartbeat error: {e}")
                await asyncio.sleep(30)  # Retry after 30s
    
    async def _heartbeat_cycle(self):
        """
        Execute one heartbeat cycle
        """
        # Get all agents in idle state
        idle_agents = self.agent_manager.get_agents_by_state("idle")
        
        for agent in idle_agents:
            context = await self._gather_context(agent)
            
            # Determine if agent should activate
            if self._should_activate(agent, context):
                new_state = self._determine_state(agent, context)
                await agent.transition(new_state, context)
                
                self.logger.info(
                    f"Agent {agent.id} activated: idle -> {new_state}"
                )
    
    async def _gather_context(self, agent) -> Dict:
        """
        Gather context for decision making
        """
        return {
            "time": time.time(),
            "user_activity": await self._check_user_activity(agent),
            "pending_tasks": await agent.get_pending_tasks(),
            "system_health": await self._check_system_health(),
            "social_updates": await self._check_social_updates(agent),
            "scheduled_events": await self._check_schedule(agent)
        }
    
    def _should_activate(self, agent, context: Dict) -> bool:
        """
        Determine if agent should leave idle state
        """
        # Check various activation triggers
        triggers = [
            context["pending_tasks"],
            context["user_activity"]["recent"],
            context["scheduled_events"]["upcoming"],
            context["system_health"]["issues"],
            context["social_updates"]["important"]
        ]
        
        return any(triggers)
```

### WebGPU Visualization Component
```typescript
// ui/src/components/WebGPURenderer.tsx
import React, { useEffect, useRef } from 'react';

class WGPURenderer {
    private device: GPUDevice | null = null;
    private context: GPUCanvasContext | null = null;
    private pipeline: GPURenderPipeline | null = null;
    
    async initialize(canvas: HTMLCanvasElement) {
        // Check WebGPU support
        if (!navigator.gpu) {
            throw new Error('WebGPU not supported');
        }
        
        // Get adapter and device
        const adapter = await navigator.gpu.requestAdapter();
        if (!adapter) {
            throw new Error('No GPU adapter found');
        }
        
        this.device = await adapter.requestDevice();
        
        // Configure canvas context
        this.context = canvas.getContext('webgpu');
        if (!this.context) {
            throw new Error('Could not get WebGPU context');
        }
        
        const format = navigator.gpu.getPreferredCanvasFormat();
        this.context.configure({
            device: this.device,
            format: format,
            alphaMode: 'premultiplied'
        });
        
        // Create render pipeline
        this.pipeline = await this.createRenderPipeline(format);
    }
    
    async stream(content: any, container: HTMLElement) {
        // Real-time streaming visualization
        // AI can update this dynamically
        const frame = () => {
            this.render(content);
            requestAnimationFrame(frame);
        };
        requestAnimationFrame(frame);
    }
    
    private async createRenderPipeline(format: GPUTextureFormat) {
        // Shader for dynamic visualization
        const shaderModule = this.device!.createShaderModule({
            code: `
                struct VertexOutput {
                    @builtin(position) position: vec4<f32>,
                    @location(0) color: vec4<f32>,
                    @location(1) uv: vec2<f32>,
                }
                
                @vertex
                fn vs_main(@builtin(vertex_index) vertex_index: u32) -> VertexOutput {
                    var output: VertexOutput;
                    // Dynamic vertex generation based on AI input
                    return output;
                }
                
                @fragment
                fn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {
                    // Dynamic fragment shading
                    return input.color;
                }
            `
        });
        
        return this.device!.createRenderPipeline({
            layout: 'auto',
            vertex: {
                module: shaderModule,
                entryPoint: 'vs_main'
            },
            fragment: {
                module: shaderModule,
                entryPoint: 'fs_main',
                targets: [{ format }]
            },
            primitive: {
                topology: 'triangle-list'
            }
        });
    }
}

export const WebGPUVisualization: React.FC = () => {
    const canvasRef = useRef<HTMLCanvasElement>(null);
    const rendererRef = useRef<WGPURenderer | null>(null);
    
    useEffect(() => {
        const initRenderer = async () => {
            if (canvasRef.current) {
                const renderer = new WGPURenderer();
                await renderer.initialize(canvasRef.current);
                rendererRef.current = renderer;
                
                // Expose to AI control
                (window as any).aiVisualizationControl = {
                    stream: (content: any) => renderer.stream(content, canvasRef.current!.parentElement!),
                    // Other control methods
                };
            }
        };
        
        initRenderer();
    }, []);
    
    return (
        <canvas 
            ref={canvasRef}
            style={{ width: '100%', height: '70vh' }}
        />
    );
};
```

### Network Discovery
```python
# core/network/discovery.py
from zeroconf import ServiceBrowser, Zeroconf, ServiceInfo
import socket
import json
from typing import List, Dict

class LocalDiscovery:
    """
    mDNS-based local network discovery
    """
    
    def __init__(self, node_id: str):
        self.node_id = node_id
        self.zeroconf = Zeroconf()
        self.services = {}
        self.service_type = "_hai-net._tcp.local."
        
    def advertise_node(self, role: str, capabilities: Dict):
        """
        Advertise this node on local network
        """
        info = ServiceInfo(
            self.service_type,
            f"{self.node_id}.{self.service_type}",
            addresses=[socket.inet_aton(self._get_local_ip())],
            port=4001,
            properties={
                "role": role,
                "capabilities": json.dumps(capabilities),
                "version": "1.0.0"
            }
        )
        
        self.zeroconf.register_service(info)
        return info
    
    def discover_nodes(self, timeout: int = 10) -> List[Dict]:
        """
        Discover other HAI-Net nodes on local network
        """
        discovered = []
        browser = ServiceBrowser(
            self.zeroconf,
            self.service_type,
            handlers=[self._on_service_state_change]
        )
        
        # Wait for discovery
        import time
        time.sleep(timeout)
        
        for name, info in self.services.items():
            discovered.append({
                "node_id": name.split('.')[0],
                "address": socket.inet_ntoa(info.addresses[0]),
                "port": info.port,
                "role": info.properties.get(b"role", b"").decode(),
                "capabilities": json.loads(
                    info.properties.get(b"capabilities", b"{}").decode()
                )
            })
        
        return discovered
    
    def _on_service_state_change(self, zeroconf, service_type, name, state_change):
        """
        Handle service discovery events
        """
        if state_change == "added":
            info = zeroconf.get_service_info(service_type, name)
            if info:
                self.services[name] = info
```

### Resource Manager
```python
# hub/master/resource_manager.py
import psutil
import GPUtil
from typing import Dict, List
import asyncio

class ResourceManager:
    """
    Manages local and surplus resources
    """
    
    def __init__(self):
        self.local_resources = {}
        self.surplus_resources = {}
        self.resource_history = []
        self.sharing_enabled = False
        
    async def assess_resources(self) -> Dict:
        """
        Assess available system resources
        """
        resources = {
            "cpu": {
                "cores": psutil.cpu_count(),
                "usage": psutil.cpu_percent(interval=1),
                "frequency": psutil.cpu_freq().current
            },
            "memory": {
                "total": psutil.virtual_memory().total,
                "available": psutil.virtual_memory().available,
                "usage": psutil.virtual_memory().percent
            },
            "storage": {
                "total": psutil.disk_usage('/').total,
                "free": psutil.disk_usage('/').free,
                "usage": psutil.disk_usage('/').percent
            }
        }
        
        # Check for GPU
        gpus = GPUtil.getGPUs()
        if gpus:
            resources["gpu"] = {
                "count": len(gpus),
                "memory_total": gpus[0].memoryTotal,
                "memory_free": gpus[0].memoryFree,
                "usage": gpus[0].load * 100
            }
        
        self.local_resources = resources
        return resources
    
    async def calculate_surplus(self) -> Dict:
        """
        Calculate surplus resources for sharing
        """
        if not self.sharing_enabled:
            return {}
        
        # Analyze usage patterns
        usage_history = await self._get_usage_history()
        peak_usage = self._calculate_peak_usage(usage_history)
        
        # Calculate surplus with safety margin
        surplus = {
            "cpu": max(0, 100 - peak_usage["cpu"] * 1.5 - 20),  # Keep 20% minimum
            "memory": max(0, self.local_resources["memory"]["available"] - 2 * 1024**3),  # Keep 2GB
            "storage": max(0, self.local_resources["storage"]["free"] - 10 * 1024**3),  # Keep 10GB
        }
        
        if "gpu" in self.local_resources:
            surplus["gpu"] = max(0, self.local_resources["gpu"]["memory_free"] - 1024)  # Keep 1GB VRAM
        
        self.surplus_resources = surplus
        return surplus
    
    def enable_sharing(self, user_consent: bool = False):
        """
        Enable surplus resource sharing with user consent
        """
        if user_consent:
            self.sharing_enabled = True
            # Start monitoring for idle resources
            asyncio.create_task(self._monitor_and_share())
```

## Deployment Strategy

### Docker Compose Configuration
```yaml
# docker-compose.yml
version: '3.8'

services:
  hai-net-master:
    build:
      context: .
      dockerfile: Dockerfile.master
    container_name: hai-net-master
    network_mode: host
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - NODE_ROLE=master
      - NODE_ID=${NODE_ID}
      - DID=${USER_DID}
    restart: unless-stopped
    
  hai-net-ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    container_name: hai-net-ui
    ports:
      - "8080:8080"
    depends_on:
      - hai-net-master
    volumes:
      - ./ui/dist:/usr/share/nginx/html
    
  redis:
    image: redis:alpine
    container_name: hai-net-cache
    volumes:
      - redis-data:/data
    
  ollama:
    image: ollama/ollama
    container_name: hai-net-llm
    volumes:
      - ollama-data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  redis-data:
  ollama-data:
```

### Installation Script
```bash
#!/bin/bash
# install/install.sh

set -e

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘     HAI-Net Installation Wizard      â•‘"
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Detect OS and architecture
OS=$(uname -s | tr '[:upper:]' '[:lower:]')
ARCH=$(uname -m)

# Check prerequisites
check_prerequisites() {
    echo "Checking prerequisites..."
    
    # Python 3.9+
    if ! command -v python3 &> /dev/null; then
        echo "âŒ Python 3.9+ is required"
        exit 1
    fi
    
    # Node.js 18+
    if ! command -v node &> /dev/null; then
        echo "âŒ Node.js 18+ is required"
        exit 1
    fi
    
    # Docker (optional but recommended)
    if command -v docker &> /dev/null; then
        echo "âœ… Docker detected"
        USE_DOCKER=true
    else
        echo "âš ï¸  Docker not found - native installation will be used"
        USE_DOCKER=false
    fi
    
    echo "âœ… Prerequisites satisfied"
}

# Create HAI-Net directory
create_directories() {
    echo "Creating HAI-Net directories..."
    
    mkdir -p ~/hai-net/{data,models,logs,config}
    cd ~/hai-net
    
    echo "âœ… Directories created"
}

# Download and extract HAI-Net
download_hai_net() {
    echo "Downloading HAI-Net..."
    
    # Use the network-hosted URL (future)
    # For now, use GitHub or similar
    wget -O hai-net.tar.gz https://hai-net.org/releases/latest.tar.gz
    tar -xzf hai-net.tar.gz
    rm hai-net.tar.gz
    
    echo "âœ… HAI-Net downloaded"
}

# Install Python dependencies
install_python_deps() {
    echo "Installing Python dependencies..."
    
    python3 -m venv venv
    source venv/bin/activate
    pip install --upgrade pip
    pip install -r requirements.txt
    
    echo "âœ… Python dependencies installed"
}

# Install Node.js dependencies
install_node_deps() {
    echo "Installing Node.js dependencies..."
    
    cd ui
    npm install
    npm run build
    cd ..
    
    echo "âœ… Node.js dependencies installed"
}

# Configure HAI-Net
configure_hai_net() {
    echo ""
    echo "Configuration"
    echo "============="
    
    # Node role selection
    echo "Select node role:"
    echo "1) Master (orchestrator)"
    echo "2) Slave (compute node)"
    read -p "Choice [1-2]: " role_choice
    
    case $role_choice in
        1)
            NODE_ROLE="master"
            ;;
        2)
            NODE_ROLE="slave"
            read -p "Enter master node address: " MASTER_ADDR
            ;;
        *)
            echo "Invalid choice"
            exit 1
            ;;
    esac
    
    # Create identity
    echo ""
    echo "Creating your HAI-Net identity..."
    python3 -c "from core.identity import create_identity; create_identity()"
    
    # Save configuration
    cat > config/node.yaml << EOF
role: $NODE_ROLE
master_address: ${MASTER_ADDR:-localhost}
created: $(date -Iseconds)
EOF
    
    echo "âœ… Configuration complete"
}

# Start HAI-Net
start_hai_net() {
    echo ""
    echo "Starting HAI-Net..."
    
    if [ "$USE_DOCKER" = true ]; then
        docker-compose up -d
    else
        # Start services natively
        ./scripts/start_services.sh
    fi
    
    echo "âœ… HAI-Net is running!"
    echo ""
    echo "Access the UI at: http://localhost:8080"
    echo ""
}

# Main installation flow
main() {
    check_prerequisites
    create_directories
    download_hai_net
    install_python_deps
    install_node_deps
    configure_hai_net
    start_hai_net
    
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘   Installation Complete! ðŸŽ‰          â•‘"
    echo "â•‘                                      â•‘"
    echo "â•‘   Welcome to HAI-Net                 â•‘"
    echo "â•‘   Building a better future together  â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
}

main "$@"
```

## Testing Framework

### Unit Test Example
```python
# tests/unit/test_identity.py
import pytest
from core.identity.did import IdentityManager

class TestIdentityManager:
    def test_did_generation(self):
        """Test DID generation is deterministic"""
        manager = IdentityManager()
        
        # Create identity
        identity1 = manager.create_identity(
            full_name="John Doe",
            date_of_birth="1990-01-01",
            gov_id="123456789",
            passphrase="secure_pass",
            email="john@example.com"
        )
        
        # Recreate with same data
        manager2 = IdentityManager()
        identity2 = manager2.create_identity(
            full_name="John Doe",
            date_of_birth="1990-01-01",
            gov_id="123456789",
            passphrase="secure_pass",
            email="john@example.com"
        )
        
        # DIDs should match
        assert identity1["did"] == identity2["did"]
    
    def test_watermarking(self):
        """Test data watermarking"""
        manager = IdentityManager()
        manager.create_identity(
            full_name="Test User",
            date_of_birth="2000-01-01",
            gov_id="987654321",
            passphrase="test_pass",
            email="test@example.com"
        )
        
        # Watermark some data
        original_data = b"This is test data"
        watermarked = manager.watermark_data(original_data)
        
        # Verify watermark is embedded
        assert watermarked != original_data
        assert manager.verify_watermark(watermarked)
```

## Documentation Template

### README.md
```markdown
# HAI-Net: Human-AI Network

A decentralized, privacy-first framework for human-AI collaboration.

## ðŸŒ Vision

Creating a sustainable, community-driven alternative to centralized AI systems.

## ðŸš€ Quick Start

```bash
curl -sSL https://hai-net.org/install.sh | bash
```

## ðŸ“– Documentation

- [Architecture Overview](docs/architecture.md)
- [Installation Guide](docs/installation.md)
- [User Guide](docs/user-guide.md)
- [API Reference](docs/api.md)
- [Contributing](docs/contributing.md)

## ðŸ¤ Community

- [Discord](https://discord.gg/hai-net)
- [Forum](https://forum.hai-net.org)
- [Matrix](https://matrix.to/#/#hai-net:matrix.org)

## ðŸ“œ License

Open Source - [LICENSE](LICENSE)

## ðŸŒ± Environmental Impact

Every idle resource shared prevents unnecessary hardware production and reduces global energy waste. Join us in building a cooler planet!
```

This implementation provides a solid foundation to begin development!